################ Profiling started at 20240129-044012 ################.
Provided parameters: profile(function=Conv2dRFFTFunction timestamp=20240129-044012 batch_size=64 profile_name=AlexNet_CIFAR10_Conv2dRFFTFunction num_classes=10 skip_first=0 wait=4 warmup=4 active=4 repeat=1)
Original model architecture is AlexNet(
  (features): Sequential(
    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))
    (1): ReLU(inplace=True)
    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)
    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (4): ReLU(inplace=True)
    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)
    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (7): ReLU(inplace=True)
    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (9): ReLU(inplace=True)
    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (11): ReLU(inplace=True)
    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))
  (classifier): Sequential(
    (0): Dropout(p=0.5, inplace=False)
    (1): Linear(in_features=9216, out_features=4096, bias=True)
    (2): ReLU(inplace=True)
    (3): Dropout(p=0.5, inplace=False)
    (4): Linear(in_features=4096, out_features=4096, bias=True)
    (5): ReLU(inplace=True)
    (6): Linear(in_features=4096, out_features=1000, bias=True)
  )
)
Adopted model architecture is AlexNet(
  (features): Sequential(
    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))
    (1): ReLU(inplace=True)
    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)
    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (4): ReLU(inplace=True)
    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)
    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (7): ReLU(inplace=True)
    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (9): ReLU(inplace=True)
    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (11): ReLU(inplace=True)
    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))
  (classifier): Sequential(
    (0): Dropout(p=0.5, inplace=False)
    (1): Linear(in_features=9216, out_features=4096, bias=True)
    (2): ReLU(inplace=True)
    (3): Dropout(p=0.5, inplace=False)
    (4): Linear(in_features=4096, out_features=4096, bias=True)
    (5): ReLU(inplace=True)
    (6): Linear(in_features=4096, out_features=10, bias=True)
  )
)
(0) parameter.requires_grad = True
(1) parameter.requires_grad = True
(2) parameter.requires_grad = True
(3) parameter.requires_grad = True
(4) parameter.requires_grad = True
(5) parameter.requires_grad = True
(6) parameter.requires_grad = True
(7) parameter.requires_grad = True
(8) parameter.requires_grad = True
(9) parameter.requires_grad = True
(10) parameter.requires_grad = True
(11) parameter.requires_grad = True
(12) parameter.requires_grad = True
(13) parameter.requires_grad = True
(14) parameter.requires_grad = True
(15) parameter.requires_grad = True
Profiling Model AlexNet_CIFAR10_Conv2dRFFTFunction.
################################################################################
Running Conv2dRFFTFunction step=0/12 (0.00%)
################################################################################
Applying built-in conv2d(input_shape=torch.Size([64, 3, 224, 224]) weights_shape=torch.Size([64, 3, 11, 11]) bias_shape=torch.Size([64]) stride=(4, 4) padding=(2, 2) dilation=(1, 1) groups=1)
Applying Conv2dRFFTFunction(input_shape=torch.Size([64, 64, 27, 27]) weights_shape=torch.Size([192, 64, 5, 5]) bias_shape=torch.Size([192]) stride=(1, 1) padding=(2, 2) dilation=(1, 1) groups=1)
Applying Conv2dRFFTFunction(input_shape=torch.Size([64, 192, 13, 13]) weights_shape=torch.Size([384, 192, 3, 3]) bias_shape=torch.Size([384]) stride=(1, 1) padding=(1, 1) dilation=(1, 1) groups=1)
Applying Conv2dRFFTFunction(input_shape=torch.Size([64, 384, 13, 13]) weights_shape=torch.Size([256, 384, 3, 3]) bias_shape=torch.Size([256]) stride=(1, 1) padding=(1, 1) dilation=(1, 1) groups=1)
Applying Conv2dRFFTFunction(input_shape=torch.Size([64, 256, 13, 13]) weights_shape=torch.Size([256, 256, 3, 3]) bias_shape=torch.Size([256]) stride=(1, 1) padding=(1, 1) dilation=(1, 1) groups=1)
[W kineto_shim.cpp:337] Profiler is not initialized: skipping step() invocation
################################################################################
Running Conv2dRFFTFunction step=1/12 (8.33%)
################################################################################
Applying built-in conv2d(input_shape=torch.Size([64, 3, 224, 224]) weights_shape=torch.Size([64, 3, 11, 11]) bias_shape=torch.Size([64]) stride=(4, 4) padding=(2, 2) dilation=(1, 1) groups=1)
Applying Conv2dRFFTFunction(input_shape=torch.Size([64, 64, 27, 27]) weights_shape=torch.Size([192, 64, 5, 5]) bias_shape=torch.Size([192]) stride=(1, 1) padding=(2, 2) dilation=(1, 1) groups=1)
Applying Conv2dRFFTFunction(input_shape=torch.Size([64, 192, 13, 13]) weights_shape=torch.Size([384, 192, 3, 3]) bias_shape=torch.Size([384]) stride=(1, 1) padding=(1, 1) dilation=(1, 1) groups=1)
Applying Conv2dRFFTFunction(input_shape=torch.Size([64, 384, 13, 13]) weights_shape=torch.Size([256, 384, 3, 3]) bias_shape=torch.Size([256]) stride=(1, 1) padding=(1, 1) dilation=(1, 1) groups=1)
Applying Conv2dRFFTFunction(input_shape=torch.Size([64, 256, 13, 13]) weights_shape=torch.Size([256, 256, 3, 3]) bias_shape=torch.Size([256]) stride=(1, 1) padding=(1, 1) dilation=(1, 1) groups=1)
[W kineto_shim.cpp:337] Profiler is not initialized: skipping step() invocation
################################################################################
Running Conv2dRFFTFunction step=2/12 (16.67%)
################################################################################
Applying built-in conv2d(input_shape=torch.Size([64, 3, 224, 224]) weights_shape=torch.Size([64, 3, 11, 11]) bias_shape=torch.Size([64]) stride=(4, 4) padding=(2, 2) dilation=(1, 1) groups=1)
Applying Conv2dRFFTFunction(input_shape=torch.Size([64, 64, 27, 27]) weights_shape=torch.Size([192, 64, 5, 5]) bias_shape=torch.Size([192]) stride=(1, 1) padding=(2, 2) dilation=(1, 1) groups=1)
Applying Conv2dRFFTFunction(input_shape=torch.Size([64, 192, 13, 13]) weights_shape=torch.Size([384, 192, 3, 3]) bias_shape=torch.Size([384]) stride=(1, 1) padding=(1, 1) dilation=(1, 1) groups=1)
Applying Conv2dRFFTFunction(input_shape=torch.Size([64, 384, 13, 13]) weights_shape=torch.Size([256, 384, 3, 3]) bias_shape=torch.Size([256]) stride=(1, 1) padding=(1, 1) dilation=(1, 1) groups=1)
Applying Conv2dRFFTFunction(input_shape=torch.Size([64, 256, 13, 13]) weights_shape=torch.Size([256, 256, 3, 3]) bias_shape=torch.Size([256]) stride=(1, 1) padding=(1, 1) dilation=(1, 1) groups=1)
[W kineto_shim.cpp:337] Profiler is not initialized: skipping step() invocation
################################################################################
Running Conv2dRFFTFunction step=3/12 (25.00%)
################################################################################
Applying built-in conv2d(input_shape=torch.Size([64, 3, 224, 224]) weights_shape=torch.Size([64, 3, 11, 11]) bias_shape=torch.Size([64]) stride=(4, 4) padding=(2, 2) dilation=(1, 1) groups=1)
Applying Conv2dRFFTFunction(input_shape=torch.Size([64, 64, 27, 27]) weights_shape=torch.Size([192, 64, 5, 5]) bias_shape=torch.Size([192]) stride=(1, 1) padding=(2, 2) dilation=(1, 1) groups=1)
Applying Conv2dRFFTFunction(input_shape=torch.Size([64, 192, 13, 13]) weights_shape=torch.Size([384, 192, 3, 3]) bias_shape=torch.Size([384]) stride=(1, 1) padding=(1, 1) dilation=(1, 1) groups=1)
Applying Conv2dRFFTFunction(input_shape=torch.Size([64, 384, 13, 13]) weights_shape=torch.Size([256, 384, 3, 3]) bias_shape=torch.Size([256]) stride=(1, 1) padding=(1, 1) dilation=(1, 1) groups=1)
Applying Conv2dRFFTFunction(input_shape=torch.Size([64, 256, 13, 13]) weights_shape=torch.Size([256, 256, 3, 3]) bias_shape=torch.Size([256]) stride=(1, 1) padding=(1, 1) dilation=(1, 1) groups=1)
################################################################################
Running Conv2dRFFTFunction step=4/12 (33.33%)
################################################################################
Applying built-in conv2d(input_shape=torch.Size([64, 3, 224, 224]) weights_shape=torch.Size([64, 3, 11, 11]) bias_shape=torch.Size([64]) stride=(4, 4) padding=(2, 2) dilation=(1, 1) groups=1)
Applying Conv2dRFFTFunction(input_shape=torch.Size([64, 64, 27, 27]) weights_shape=torch.Size([192, 64, 5, 5]) bias_shape=torch.Size([192]) stride=(1, 1) padding=(2, 2) dilation=(1, 1) groups=1)
Applying Conv2dRFFTFunction(input_shape=torch.Size([64, 192, 13, 13]) weights_shape=torch.Size([384, 192, 3, 3]) bias_shape=torch.Size([384]) stride=(1, 1) padding=(1, 1) dilation=(1, 1) groups=1)
Applying Conv2dRFFTFunction(input_shape=torch.Size([64, 384, 13, 13]) weights_shape=torch.Size([256, 384, 3, 3]) bias_shape=torch.Size([256]) stride=(1, 1) padding=(1, 1) dilation=(1, 1) groups=1)
Applying Conv2dRFFTFunction(input_shape=torch.Size([64, 256, 13, 13]) weights_shape=torch.Size([256, 256, 3, 3]) bias_shape=torch.Size([256]) stride=(1, 1) padding=(1, 1) dilation=(1, 1) groups=1)
################################################################################
Running Conv2dRFFTFunction step=5/12 (41.67%)
################################################################################
Applying built-in conv2d(input_shape=torch.Size([64, 3, 224, 224]) weights_shape=torch.Size([64, 3, 11, 11]) bias_shape=torch.Size([64]) stride=(4, 4) padding=(2, 2) dilation=(1, 1) groups=1)
Applying Conv2dRFFTFunction(input_shape=torch.Size([64, 64, 27, 27]) weights_shape=torch.Size([192, 64, 5, 5]) bias_shape=torch.Size([192]) stride=(1, 1) padding=(2, 2) dilation=(1, 1) groups=1)
Applying Conv2dRFFTFunction(input_shape=torch.Size([64, 192, 13, 13]) weights_shape=torch.Size([384, 192, 3, 3]) bias_shape=torch.Size([384]) stride=(1, 1) padding=(1, 1) dilation=(1, 1) groups=1)
Applying Conv2dRFFTFunction(input_shape=torch.Size([64, 384, 13, 13]) weights_shape=torch.Size([256, 384, 3, 3]) bias_shape=torch.Size([256]) stride=(1, 1) padding=(1, 1) dilation=(1, 1) groups=1)
Applying Conv2dRFFTFunction(input_shape=torch.Size([64, 256, 13, 13]) weights_shape=torch.Size([256, 256, 3, 3]) bias_shape=torch.Size([256]) stride=(1, 1) padding=(1, 1) dilation=(1, 1) groups=1)
################################################################################
Running Conv2dRFFTFunction step=6/12 (50.00%)
################################################################################
Applying built-in conv2d(input_shape=torch.Size([64, 3, 224, 224]) weights_shape=torch.Size([64, 3, 11, 11]) bias_shape=torch.Size([64]) stride=(4, 4) padding=(2, 2) dilation=(1, 1) groups=1)
Applying Conv2dRFFTFunction(input_shape=torch.Size([64, 64, 27, 27]) weights_shape=torch.Size([192, 64, 5, 5]) bias_shape=torch.Size([192]) stride=(1, 1) padding=(2, 2) dilation=(1, 1) groups=1)
Applying Conv2dRFFTFunction(input_shape=torch.Size([64, 192, 13, 13]) weights_shape=torch.Size([384, 192, 3, 3]) bias_shape=torch.Size([384]) stride=(1, 1) padding=(1, 1) dilation=(1, 1) groups=1)
Applying Conv2dRFFTFunction(input_shape=torch.Size([64, 384, 13, 13]) weights_shape=torch.Size([256, 384, 3, 3]) bias_shape=torch.Size([256]) stride=(1, 1) padding=(1, 1) dilation=(1, 1) groups=1)
Applying Conv2dRFFTFunction(input_shape=torch.Size([64, 256, 13, 13]) weights_shape=torch.Size([256, 256, 3, 3]) bias_shape=torch.Size([256]) stride=(1, 1) padding=(1, 1) dilation=(1, 1) groups=1)
################################################################################
Running Conv2dRFFTFunction step=7/12 (58.33%)
################################################################################
Applying built-in conv2d(input_shape=torch.Size([64, 3, 224, 224]) weights_shape=torch.Size([64, 3, 11, 11]) bias_shape=torch.Size([64]) stride=(4, 4) padding=(2, 2) dilation=(1, 1) groups=1)
Applying Conv2dRFFTFunction(input_shape=torch.Size([64, 64, 27, 27]) weights_shape=torch.Size([192, 64, 5, 5]) bias_shape=torch.Size([192]) stride=(1, 1) padding=(2, 2) dilation=(1, 1) groups=1)
Applying Conv2dRFFTFunction(input_shape=torch.Size([64, 192, 13, 13]) weights_shape=torch.Size([384, 192, 3, 3]) bias_shape=torch.Size([384]) stride=(1, 1) padding=(1, 1) dilation=(1, 1) groups=1)
Applying Conv2dRFFTFunction(input_shape=torch.Size([64, 384, 13, 13]) weights_shape=torch.Size([256, 384, 3, 3]) bias_shape=torch.Size([256]) stride=(1, 1) padding=(1, 1) dilation=(1, 1) groups=1)
Applying Conv2dRFFTFunction(input_shape=torch.Size([64, 256, 13, 13]) weights_shape=torch.Size([256, 256, 3, 3]) bias_shape=torch.Size([256]) stride=(1, 1) padding=(1, 1) dilation=(1, 1) groups=1)
################################################################################
Running Conv2dRFFTFunction step=8/12 (66.67%)
################################################################################
[W CPUAllocator.cpp:219] Memory block of unknown size was allocated before the profiling started, profiler results will not include the deallocation event
Applying built-in conv2d(input_shape=torch.Size([64, 3, 224, 224]) weights_shape=torch.Size([64, 3, 11, 11]) bias_shape=torch.Size([64]) stride=(4, 4) padding=(2, 2) dilation=(1, 1) groups=1)
Applying Conv2dRFFTFunction(input_shape=torch.Size([64, 64, 27, 27]) weights_shape=torch.Size([192, 64, 5, 5]) bias_shape=torch.Size([192]) stride=(1, 1) padding=(2, 2) dilation=(1, 1) groups=1)
Applying Conv2dRFFTFunction(input_shape=torch.Size([64, 192, 13, 13]) weights_shape=torch.Size([384, 192, 3, 3]) bias_shape=torch.Size([384]) stride=(1, 1) padding=(1, 1) dilation=(1, 1) groups=1)
Applying Conv2dRFFTFunction(input_shape=torch.Size([64, 384, 13, 13]) weights_shape=torch.Size([256, 384, 3, 3]) bias_shape=torch.Size([256]) stride=(1, 1) padding=(1, 1) dilation=(1, 1) groups=1)
Applying Conv2dRFFTFunction(input_shape=torch.Size([64, 256, 13, 13]) weights_shape=torch.Size([256, 256, 3, 3]) bias_shape=torch.Size([256]) stride=(1, 1) padding=(1, 1) dilation=(1, 1) groups=1)
################################################################################
Running Conv2dRFFTFunction step=9/12 (75.00%)
################################################################################
Applying built-in conv2d(input_shape=torch.Size([64, 3, 224, 224]) weights_shape=torch.Size([64, 3, 11, 11]) bias_shape=torch.Size([64]) stride=(4, 4) padding=(2, 2) dilation=(1, 1) groups=1)
Applying Conv2dRFFTFunction(input_shape=torch.Size([64, 64, 27, 27]) weights_shape=torch.Size([192, 64, 5, 5]) bias_shape=torch.Size([192]) stride=(1, 1) padding=(2, 2) dilation=(1, 1) groups=1)
Applying Conv2dRFFTFunction(input_shape=torch.Size([64, 192, 13, 13]) weights_shape=torch.Size([384, 192, 3, 3]) bias_shape=torch.Size([384]) stride=(1, 1) padding=(1, 1) dilation=(1, 1) groups=1)
Applying Conv2dRFFTFunction(input_shape=torch.Size([64, 384, 13, 13]) weights_shape=torch.Size([256, 384, 3, 3]) bias_shape=torch.Size([256]) stride=(1, 1) padding=(1, 1) dilation=(1, 1) groups=1)
Applying Conv2dRFFTFunction(input_shape=torch.Size([64, 256, 13, 13]) weights_shape=torch.Size([256, 256, 3, 3]) bias_shape=torch.Size([256]) stride=(1, 1) padding=(1, 1) dilation=(1, 1) groups=1)
################################################################################
Running Conv2dRFFTFunction step=10/12 (83.33%)
################################################################################
Applying built-in conv2d(input_shape=torch.Size([64, 3, 224, 224]) weights_shape=torch.Size([64, 3, 11, 11]) bias_shape=torch.Size([64]) stride=(4, 4) padding=(2, 2) dilation=(1, 1) groups=1)
Applying Conv2dRFFTFunction(input_shape=torch.Size([64, 64, 27, 27]) weights_shape=torch.Size([192, 64, 5, 5]) bias_shape=torch.Size([192]) stride=(1, 1) padding=(2, 2) dilation=(1, 1) groups=1)
Applying Conv2dRFFTFunction(input_shape=torch.Size([64, 192, 13, 13]) weights_shape=torch.Size([384, 192, 3, 3]) bias_shape=torch.Size([384]) stride=(1, 1) padding=(1, 1) dilation=(1, 1) groups=1)
Applying Conv2dRFFTFunction(input_shape=torch.Size([64, 384, 13, 13]) weights_shape=torch.Size([256, 384, 3, 3]) bias_shape=torch.Size([256]) stride=(1, 1) padding=(1, 1) dilation=(1, 1) groups=1)
Applying Conv2dRFFTFunction(input_shape=torch.Size([64, 256, 13, 13]) weights_shape=torch.Size([256, 256, 3, 3]) bias_shape=torch.Size([256]) stride=(1, 1) padding=(1, 1) dilation=(1, 1) groups=1)
################################################################################
Running Conv2dRFFTFunction step=11/12 (91.67%)
################################################################################
Applying built-in conv2d(input_shape=torch.Size([64, 3, 224, 224]) weights_shape=torch.Size([64, 3, 11, 11]) bias_shape=torch.Size([64]) stride=(4, 4) padding=(2, 2) dilation=(1, 1) groups=1)
Applying Conv2dRFFTFunction(input_shape=torch.Size([64, 64, 27, 27]) weights_shape=torch.Size([192, 64, 5, 5]) bias_shape=torch.Size([192]) stride=(1, 1) padding=(2, 2) dilation=(1, 1) groups=1)
Applying Conv2dRFFTFunction(input_shape=torch.Size([64, 192, 13, 13]) weights_shape=torch.Size([384, 192, 3, 3]) bias_shape=torch.Size([384]) stride=(1, 1) padding=(1, 1) dilation=(1, 1) groups=1)
Applying Conv2dRFFTFunction(input_shape=torch.Size([64, 384, 13, 13]) weights_shape=torch.Size([256, 384, 3, 3]) bias_shape=torch.Size([256]) stride=(1, 1) padding=(1, 1) dilation=(1, 1) groups=1)
Applying Conv2dRFFTFunction(input_shape=torch.Size([64, 256, 13, 13]) weights_shape=torch.Size([256, 256, 3, 3]) bias_shape=torch.Size([256]) stride=(1, 1) padding=(1, 1) dilation=(1, 1) groups=1)
################################################################################
Profile trace saved to /home/edreis/Code/eduardo4jesus/Phd-Research/paper2/src/experiments/.profiles/AlexNet_CIFAR10_Conv2dRFFTFunction_date-20240129-044012.json.
Profile saved to /home/edreis/Code/eduardo4jesus/Phd-Research/paper2/src/experiments/.profiles/AlexNet_CIFAR10_Conv2dRFFTFunction_date-20240129-044012.pt.
Provided parameters: profile(function=Conv2dRFFTPhasorFunction timestamp=20240129-044012 batch_size=64 profile_name=AlexNet_CIFAR10_Conv2dRFFTPhasorFunction num_classes=10 skip_first=0 wait=4 warmup=4 active=4 repeat=1)
Original model architecture is AlexNet(
  (features): Sequential(
    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))
    (1): ReLU(inplace=True)
    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)
    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (4): ReLU(inplace=True)
    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)
    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (7): ReLU(inplace=True)
    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (9): ReLU(inplace=True)
    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (11): ReLU(inplace=True)
    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))
  (classifier): Sequential(
    (0): Dropout(p=0.5, inplace=False)
    (1): Linear(in_features=9216, out_features=4096, bias=True)
    (2): ReLU(inplace=True)
    (3): Dropout(p=0.5, inplace=False)
    (4): Linear(in_features=4096, out_features=4096, bias=True)
    (5): ReLU(inplace=True)
    (6): Linear(in_features=4096, out_features=1000, bias=True)
  )
)
Adopted model architecture is AlexNet(
  (features): Sequential(
    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))
    (1): ReLU(inplace=True)
    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)
    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (4): ReLU(inplace=True)
    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)
    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (7): ReLU(inplace=True)
    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (9): ReLU(inplace=True)
    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (11): ReLU(inplace=True)
    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))
  (classifier): Sequential(
    (0): Dropout(p=0.5, inplace=False)
    (1): Linear(in_features=9216, out_features=4096, bias=True)
    (2): ReLU(inplace=True)
    (3): Dropout(p=0.5, inplace=False)
    (4): Linear(in_features=4096, out_features=4096, bias=True)
    (5): ReLU(inplace=True)
    (6): Linear(in_features=4096, out_features=10, bias=True)
  )
)
(0) parameter.requires_grad = True
(1) parameter.requires_grad = True
(2) parameter.requires_grad = True
(3) parameter.requires_grad = True
(4) parameter.requires_grad = True
(5) parameter.requires_grad = True
(6) parameter.requires_grad = True
(7) parameter.requires_grad = True
(8) parameter.requires_grad = True
(9) parameter.requires_grad = True
(10) parameter.requires_grad = True
(11) parameter.requires_grad = True
(12) parameter.requires_grad = True
(13) parameter.requires_grad = True
(14) parameter.requires_grad = True
(15) parameter.requires_grad = True
Profiling Model AlexNet_CIFAR10_Conv2dRFFTPhasorFunction.
################################################################################
Running Conv2dRFFTPhasorFunction step=0/12 (0.00%)
################################################################################
Applying built-in conv2d(input_shape=torch.Size([64, 3, 224, 224]) weights_shape=torch.Size([64, 3, 11, 11]) bias_shape=torch.Size([64]) stride=(4, 4) padding=(2, 2) dilation=(1, 1) groups=1)
Applying Conv2dRFFTPhasorFunction(input_shape=torch.Size([64, 64, 27, 27]) weights_shape=torch.Size([192, 64, 5, 5]) bias_shape=torch.Size([192]) stride=(1, 1) padding=(2, 2) dilation=(1, 1) groups=1)
Applying Conv2dRFFTPhasorFunction(input_shape=torch.Size([64, 192, 13, 13]) weights_shape=torch.Size([384, 192, 3, 3]) bias_shape=torch.Size([384]) stride=(1, 1) padding=(1, 1) dilation=(1, 1) groups=1)
Applying Conv2dRFFTPhasorFunction(input_shape=torch.Size([64, 384, 13, 13]) weights_shape=torch.Size([256, 384, 3, 3]) bias_shape=torch.Size([256]) stride=(1, 1) padding=(1, 1) dilation=(1, 1) groups=1)
Applying Conv2dRFFTPhasorFunction(input_shape=torch.Size([64, 256, 13, 13]) weights_shape=torch.Size([256, 256, 3, 3]) bias_shape=torch.Size([256]) stride=(1, 1) padding=(1, 1) dilation=(1, 1) groups=1)
################################################################################
Running Conv2dRFFTPhasorFunction step=1/12 (8.33%)
################################################################################
Applying built-in conv2d(input_shape=torch.Size([64, 3, 224, 224]) weights_shape=torch.Size([64, 3, 11, 11]) bias_shape=torch.Size([64]) stride=(4, 4) padding=(2, 2) dilation=(1, 1) groups=1)
Applying Conv2dRFFTPhasorFunction(input_shape=torch.Size([64, 64, 27, 27]) weights_shape=torch.Size([192, 64, 5, 5]) bias_shape=torch.Size([192]) stride=(1, 1) padding=(2, 2) dilation=(1, 1) groups=1)
Applying Conv2dRFFTPhasorFunction(input_shape=torch.Size([64, 192, 13, 13]) weights_shape=torch.Size([384, 192, 3, 3]) bias_shape=torch.Size([384]) stride=(1, 1) padding=(1, 1) dilation=(1, 1) groups=1)
Applying Conv2dRFFTPhasorFunction(input_shape=torch.Size([64, 384, 13, 13]) weights_shape=torch.Size([256, 384, 3, 3]) bias_shape=torch.Size([256]) stride=(1, 1) padding=(1, 1) dilation=(1, 1) groups=1)
Applying Conv2dRFFTPhasorFunction(input_shape=torch.Size([64, 256, 13, 13]) weights_shape=torch.Size([256, 256, 3, 3]) bias_shape=torch.Size([256]) stride=(1, 1) padding=(1, 1) dilation=(1, 1) groups=1)
################################################################################
Running Conv2dRFFTPhasorFunction step=2/12 (16.67%)
################################################################################
Applying built-in conv2d(input_shape=torch.Size([64, 3, 224, 224]) weights_shape=torch.Size([64, 3, 11, 11]) bias_shape=torch.Size([64]) stride=(4, 4) padding=(2, 2) dilation=(1, 1) groups=1)
Applying Conv2dRFFTPhasorFunction(input_shape=torch.Size([64, 64, 27, 27]) weights_shape=torch.Size([192, 64, 5, 5]) bias_shape=torch.Size([192]) stride=(1, 1) padding=(2, 2) dilation=(1, 1) groups=1)
Applying Conv2dRFFTPhasorFunction(input_shape=torch.Size([64, 192, 13, 13]) weights_shape=torch.Size([384, 192, 3, 3]) bias_shape=torch.Size([384]) stride=(1, 1) padding=(1, 1) dilation=(1, 1) groups=1)
Applying Conv2dRFFTPhasorFunction(input_shape=torch.Size([64, 384, 13, 13]) weights_shape=torch.Size([256, 384, 3, 3]) bias_shape=torch.Size([256]) stride=(1, 1) padding=(1, 1) dilation=(1, 1) groups=1)
Applying Conv2dRFFTPhasorFunction(input_shape=torch.Size([64, 256, 13, 13]) weights_shape=torch.Size([256, 256, 3, 3]) bias_shape=torch.Size([256]) stride=(1, 1) padding=(1, 1) dilation=(1, 1) groups=1)
################################################################################
Running Conv2dRFFTPhasorFunction step=3/12 (25.00%)
################################################################################
Applying built-in conv2d(input_shape=torch.Size([64, 3, 224, 224]) weights_shape=torch.Size([64, 3, 11, 11]) bias_shape=torch.Size([64]) stride=(4, 4) padding=(2, 2) dilation=(1, 1) groups=1)
Applying Conv2dRFFTPhasorFunction(input_shape=torch.Size([64, 64, 27, 27]) weights_shape=torch.Size([192, 64, 5, 5]) bias_shape=torch.Size([192]) stride=(1, 1) padding=(2, 2) dilation=(1, 1) groups=1)
Applying Conv2dRFFTPhasorFunction(input_shape=torch.Size([64, 192, 13, 13]) weights_shape=torch.Size([384, 192, 3, 3]) bias_shape=torch.Size([384]) stride=(1, 1) padding=(1, 1) dilation=(1, 1) groups=1)
Applying Conv2dRFFTPhasorFunction(input_shape=torch.Size([64, 384, 13, 13]) weights_shape=torch.Size([256, 384, 3, 3]) bias_shape=torch.Size([256]) stride=(1, 1) padding=(1, 1) dilation=(1, 1) groups=1)
Applying Conv2dRFFTPhasorFunction(input_shape=torch.Size([64, 256, 13, 13]) weights_shape=torch.Size([256, 256, 3, 3]) bias_shape=torch.Size([256]) stride=(1, 1) padding=(1, 1) dilation=(1, 1) groups=1)
################################################################################
Running Conv2dRFFTPhasorFunction step=4/12 (33.33%)
################################################################################
Applying built-in conv2d(input_shape=torch.Size([64, 3, 224, 224]) weights_shape=torch.Size([64, 3, 11, 11]) bias_shape=torch.Size([64]) stride=(4, 4) padding=(2, 2) dilation=(1, 1) groups=1)
Applying Conv2dRFFTPhasorFunction(input_shape=torch.Size([64, 64, 27, 27]) weights_shape=torch.Size([192, 64, 5, 5]) bias_shape=torch.Size([192]) stride=(1, 1) padding=(2, 2) dilation=(1, 1) groups=1)
Applying Conv2dRFFTPhasorFunction(input_shape=torch.Size([64, 192, 13, 13]) weights_shape=torch.Size([384, 192, 3, 3]) bias_shape=torch.Size([384]) stride=(1, 1) padding=(1, 1) dilation=(1, 1) groups=1)
Applying Conv2dRFFTPhasorFunction(input_shape=torch.Size([64, 384, 13, 13]) weights_shape=torch.Size([256, 384, 3, 3]) bias_shape=torch.Size([256]) stride=(1, 1) padding=(1, 1) dilation=(1, 1) groups=1)
Applying Conv2dRFFTPhasorFunction(input_shape=torch.Size([64, 256, 13, 13]) weights_shape=torch.Size([256, 256, 3, 3]) bias_shape=torch.Size([256]) stride=(1, 1) padding=(1, 1) dilation=(1, 1) groups=1)
################################################################################
Running Conv2dRFFTPhasorFunction step=5/12 (41.67%)
################################################################################
Applying built-in conv2d(input_shape=torch.Size([64, 3, 224, 224]) weights_shape=torch.Size([64, 3, 11, 11]) bias_shape=torch.Size([64]) stride=(4, 4) padding=(2, 2) dilation=(1, 1) groups=1)
Applying Conv2dRFFTPhasorFunction(input_shape=torch.Size([64, 64, 27, 27]) weights_shape=torch.Size([192, 64, 5, 5]) bias_shape=torch.Size([192]) stride=(1, 1) padding=(2, 2) dilation=(1, 1) groups=1)
Applying Conv2dRFFTPhasorFunction(input_shape=torch.Size([64, 192, 13, 13]) weights_shape=torch.Size([384, 192, 3, 3]) bias_shape=torch.Size([384]) stride=(1, 1) padding=(1, 1) dilation=(1, 1) groups=1)
Applying Conv2dRFFTPhasorFunction(input_shape=torch.Size([64, 384, 13, 13]) weights_shape=torch.Size([256, 384, 3, 3]) bias_shape=torch.Size([256]) stride=(1, 1) padding=(1, 1) dilation=(1, 1) groups=1)
Applying Conv2dRFFTPhasorFunction(input_shape=torch.Size([64, 256, 13, 13]) weights_shape=torch.Size([256, 256, 3, 3]) bias_shape=torch.Size([256]) stride=(1, 1) padding=(1, 1) dilation=(1, 1) groups=1)
################################################################################
Running Conv2dRFFTPhasorFunction step=6/12 (50.00%)
################################################################################
Applying built-in conv2d(input_shape=torch.Size([64, 3, 224, 224]) weights_shape=torch.Size([64, 3, 11, 11]) bias_shape=torch.Size([64]) stride=(4, 4) padding=(2, 2) dilation=(1, 1) groups=1)
Applying Conv2dRFFTPhasorFunction(input_shape=torch.Size([64, 64, 27, 27]) weights_shape=torch.Size([192, 64, 5, 5]) bias_shape=torch.Size([192]) stride=(1, 1) padding=(2, 2) dilation=(1, 1) groups=1)
Applying Conv2dRFFTPhasorFunction(input_shape=torch.Size([64, 192, 13, 13]) weights_shape=torch.Size([384, 192, 3, 3]) bias_shape=torch.Size([384]) stride=(1, 1) padding=(1, 1) dilation=(1, 1) groups=1)
Applying Conv2dRFFTPhasorFunction(input_shape=torch.Size([64, 384, 13, 13]) weights_shape=torch.Size([256, 384, 3, 3]) bias_shape=torch.Size([256]) stride=(1, 1) padding=(1, 1) dilation=(1, 1) groups=1)
Applying Conv2dRFFTPhasorFunction(input_shape=torch.Size([64, 256, 13, 13]) weights_shape=torch.Size([256, 256, 3, 3]) bias_shape=torch.Size([256]) stride=(1, 1) padding=(1, 1) dilation=(1, 1) groups=1)
################################################################################
Running Conv2dRFFTPhasorFunction step=7/12 (58.33%)
################################################################################
Applying built-in conv2d(input_shape=torch.Size([64, 3, 224, 224]) weights_shape=torch.Size([64, 3, 11, 11]) bias_shape=torch.Size([64]) stride=(4, 4) padding=(2, 2) dilation=(1, 1) groups=1)
Applying Conv2dRFFTPhasorFunction(input_shape=torch.Size([64, 64, 27, 27]) weights_shape=torch.Size([192, 64, 5, 5]) bias_shape=torch.Size([192]) stride=(1, 1) padding=(2, 2) dilation=(1, 1) groups=1)
Applying Conv2dRFFTPhasorFunction(input_shape=torch.Size([64, 192, 13, 13]) weights_shape=torch.Size([384, 192, 3, 3]) bias_shape=torch.Size([384]) stride=(1, 1) padding=(1, 1) dilation=(1, 1) groups=1)
Applying Conv2dRFFTPhasorFunction(input_shape=torch.Size([64, 384, 13, 13]) weights_shape=torch.Size([256, 384, 3, 3]) bias_shape=torch.Size([256]) stride=(1, 1) padding=(1, 1) dilation=(1, 1) groups=1)
Applying Conv2dRFFTPhasorFunction(input_shape=torch.Size([64, 256, 13, 13]) weights_shape=torch.Size([256, 256, 3, 3]) bias_shape=torch.Size([256]) stride=(1, 1) padding=(1, 1) dilation=(1, 1) groups=1)
################################################################################
Running Conv2dRFFTPhasorFunction step=8/12 (66.67%)
################################################################################
Applying built-in conv2d(input_shape=torch.Size([64, 3, 224, 224]) weights_shape=torch.Size([64, 3, 11, 11]) bias_shape=torch.Size([64]) stride=(4, 4) padding=(2, 2) dilation=(1, 1) groups=1)
Applying Conv2dRFFTPhasorFunction(input_shape=torch.Size([64, 64, 27, 27]) weights_shape=torch.Size([192, 64, 5, 5]) bias_shape=torch.Size([192]) stride=(1, 1) padding=(2, 2) dilation=(1, 1) groups=1)
Applying Conv2dRFFTPhasorFunction(input_shape=torch.Size([64, 192, 13, 13]) weights_shape=torch.Size([384, 192, 3, 3]) bias_shape=torch.Size([384]) stride=(1, 1) padding=(1, 1) dilation=(1, 1) groups=1)
Applying Conv2dRFFTPhasorFunction(input_shape=torch.Size([64, 384, 13, 13]) weights_shape=torch.Size([256, 384, 3, 3]) bias_shape=torch.Size([256]) stride=(1, 1) padding=(1, 1) dilation=(1, 1) groups=1)
Applying Conv2dRFFTPhasorFunction(input_shape=torch.Size([64, 256, 13, 13]) weights_shape=torch.Size([256, 256, 3, 3]) bias_shape=torch.Size([256]) stride=(1, 1) padding=(1, 1) dilation=(1, 1) groups=1)
################################################################################
Running Conv2dRFFTPhasorFunction step=9/12 (75.00%)
################################################################################
Applying built-in conv2d(input_shape=torch.Size([64, 3, 224, 224]) weights_shape=torch.Size([64, 3, 11, 11]) bias_shape=torch.Size([64]) stride=(4, 4) padding=(2, 2) dilation=(1, 1) groups=1)
Applying Conv2dRFFTPhasorFunction(input_shape=torch.Size([64, 64, 27, 27]) weights_shape=torch.Size([192, 64, 5, 5]) bias_shape=torch.Size([192]) stride=(1, 1) padding=(2, 2) dilation=(1, 1) groups=1)
Applying Conv2dRFFTPhasorFunction(input_shape=torch.Size([64, 192, 13, 13]) weights_shape=torch.Size([384, 192, 3, 3]) bias_shape=torch.Size([384]) stride=(1, 1) padding=(1, 1) dilation=(1, 1) groups=1)
Applying Conv2dRFFTPhasorFunction(input_shape=torch.Size([64, 384, 13, 13]) weights_shape=torch.Size([256, 384, 3, 3]) bias_shape=torch.Size([256]) stride=(1, 1) padding=(1, 1) dilation=(1, 1) groups=1)
Applying Conv2dRFFTPhasorFunction(input_shape=torch.Size([64, 256, 13, 13]) weights_shape=torch.Size([256, 256, 3, 3]) bias_shape=torch.Size([256]) stride=(1, 1) padding=(1, 1) dilation=(1, 1) groups=1)
################################################################################
Running Conv2dRFFTPhasorFunction step=10/12 (83.33%)
################################################################################
Applying built-in conv2d(input_shape=torch.Size([64, 3, 224, 224]) weights_shape=torch.Size([64, 3, 11, 11]) bias_shape=torch.Size([64]) stride=(4, 4) padding=(2, 2) dilation=(1, 1) groups=1)
Applying Conv2dRFFTPhasorFunction(input_shape=torch.Size([64, 64, 27, 27]) weights_shape=torch.Size([192, 64, 5, 5]) bias_shape=torch.Size([192]) stride=(1, 1) padding=(2, 2) dilation=(1, 1) groups=1)
Applying Conv2dRFFTPhasorFunction(input_shape=torch.Size([64, 192, 13, 13]) weights_shape=torch.Size([384, 192, 3, 3]) bias_shape=torch.Size([384]) stride=(1, 1) padding=(1, 1) dilation=(1, 1) groups=1)
Applying Conv2dRFFTPhasorFunction(input_shape=torch.Size([64, 384, 13, 13]) weights_shape=torch.Size([256, 384, 3, 3]) bias_shape=torch.Size([256]) stride=(1, 1) padding=(1, 1) dilation=(1, 1) groups=1)
Applying Conv2dRFFTPhasorFunction(input_shape=torch.Size([64, 256, 13, 13]) weights_shape=torch.Size([256, 256, 3, 3]) bias_shape=torch.Size([256]) stride=(1, 1) padding=(1, 1) dilation=(1, 1) groups=1)
################################################################################
Running Conv2dRFFTPhasorFunction step=11/12 (91.67%)
################################################################################
Applying built-in conv2d(input_shape=torch.Size([64, 3, 224, 224]) weights_shape=torch.Size([64, 3, 11, 11]) bias_shape=torch.Size([64]) stride=(4, 4) padding=(2, 2) dilation=(1, 1) groups=1)
Applying Conv2dRFFTPhasorFunction(input_shape=torch.Size([64, 64, 27, 27]) weights_shape=torch.Size([192, 64, 5, 5]) bias_shape=torch.Size([192]) stride=(1, 1) padding=(2, 2) dilation=(1, 1) groups=1)
Applying Conv2dRFFTPhasorFunction(input_shape=torch.Size([64, 192, 13, 13]) weights_shape=torch.Size([384, 192, 3, 3]) bias_shape=torch.Size([384]) stride=(1, 1) padding=(1, 1) dilation=(1, 1) groups=1)
Applying Conv2dRFFTPhasorFunction(input_shape=torch.Size([64, 384, 13, 13]) weights_shape=torch.Size([256, 384, 3, 3]) bias_shape=torch.Size([256]) stride=(1, 1) padding=(1, 1) dilation=(1, 1) groups=1)
Applying Conv2dRFFTPhasorFunction(input_shape=torch.Size([64, 256, 13, 13]) weights_shape=torch.Size([256, 256, 3, 3]) bias_shape=torch.Size([256]) stride=(1, 1) padding=(1, 1) dilation=(1, 1) groups=1)
################################################################################
Profile trace saved to /home/edreis/Code/eduardo4jesus/Phd-Research/paper2/src/experiments/.profiles/AlexNet_CIFAR10_Conv2dRFFTPhasorFunction_date-20240129-044012.json.
Profile saved to /home/edreis/Code/eduardo4jesus/Phd-Research/paper2/src/experiments/.profiles/AlexNet_CIFAR10_Conv2dRFFTPhasorFunction_date-20240129-044012.pt.
################ Profiling ended at 20240129-044134 ################.
