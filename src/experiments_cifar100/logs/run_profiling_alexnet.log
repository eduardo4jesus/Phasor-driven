[0m################ Profiling started at 20240212-071549 ################.[0m
[0mProvided parameters: profile(function=Conv2dRFFTFunction timestamp=20240212-071549 batch_size=64 profile_name=AlexNet_CIFAR100_Conv2dRFFTFunction num_classes=100 skip_first=0 wait=4 warmup=4 active=4 repeat=1)[0m
[0mOriginal model architecture is AlexNet(
  (features): Sequential(
    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))
    (1): ReLU(inplace=True)
    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)
    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (4): ReLU(inplace=True)
    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)
    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (7): ReLU(inplace=True)
    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (9): ReLU(inplace=True)
    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (11): ReLU(inplace=True)
    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))
  (classifier): Sequential(
    (0): Dropout(p=0.5, inplace=False)
    (1): Linear(in_features=9216, out_features=4096, bias=True)
    (2): ReLU(inplace=True)
    (3): Dropout(p=0.5, inplace=False)
    (4): Linear(in_features=4096, out_features=4096, bias=True)
    (5): ReLU(inplace=True)
    (6): Linear(in_features=4096, out_features=1000, bias=True)
  )
)[0m
[0mAdopted model architecture is AlexNet(
  (features): Sequential(
    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))
    (1): ReLU(inplace=True)
    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)
    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (4): ReLU(inplace=True)
    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)
    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (7): ReLU(inplace=True)
    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (9): ReLU(inplace=True)
    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (11): ReLU(inplace=True)
    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))
  (classifier): Sequential(
    (0): Dropout(p=0.5, inplace=False)
    (1): Linear(in_features=9216, out_features=4096, bias=True)
    (2): ReLU(inplace=True)
    (3): Dropout(p=0.5, inplace=False)
    (4): Linear(in_features=4096, out_features=4096, bias=True)
    (5): ReLU(inplace=True)
    (6): Linear(in_features=4096, out_features=100, bias=True)
  )
)[0m
[0m(0) parameter.requires_grad = True[0m
[0m(1) parameter.requires_grad = True[0m
[0m(2) parameter.requires_grad = True[0m
[0m(3) parameter.requires_grad = True[0m
[0m(4) parameter.requires_grad = True[0m
[0m(5) parameter.requires_grad = True[0m
[0m(6) parameter.requires_grad = True[0m
[0m(7) parameter.requires_grad = True[0m
[0m(8) parameter.requires_grad = True[0m
[0m(9) parameter.requires_grad = True[0m
[0m(10) parameter.requires_grad = True[0m
[0m(11) parameter.requires_grad = True[0m
[0m(12) parameter.requires_grad = True[0m
[0m(13) parameter.requires_grad = True[0m
[0m(14) parameter.requires_grad = True[0m
[0m(15) parameter.requires_grad = True[0m
[0mProfiling Model AlexNet_CIFAR100_Conv2dRFFTFunction.[0m
[0m################################################################################[0m
[0mRunning Conv2dRFFTFunction step=0/12 (0.00%)[0m
[0m################################################################################[0m
[W kineto_shim.cpp:337] Profiler is not initialized: skipping step() invocation
[0m################################################################################[0m
[0mRunning Conv2dRFFTFunction step=1/12 (8.33%)[0m
[0m################################################################################[0m
[W kineto_shim.cpp:337] Profiler is not initialized: skipping step() invocation
[0m################################################################################[0m
[0mRunning Conv2dRFFTFunction step=2/12 (16.67%)[0m
[0m################################################################################[0m
[W kineto_shim.cpp:337] Profiler is not initialized: skipping step() invocation
[0m################################################################################[0m
[0mRunning Conv2dRFFTFunction step=3/12 (25.00%)[0m
[0m################################################################################[0m
[0m################################################################################[0m
[0mRunning Conv2dRFFTFunction step=4/12 (33.33%)[0m
[0m################################################################################[0m
[0m################################################################################[0m
[0mRunning Conv2dRFFTFunction step=5/12 (41.67%)[0m
[0m################################################################################[0m
[0m################################################################################[0m
[0mRunning Conv2dRFFTFunction step=6/12 (50.00%)[0m
[0m################################################################################[0m
[0m################################################################################[0m
[0mRunning Conv2dRFFTFunction step=7/12 (58.33%)[0m
[0m################################################################################[0m
[0m################################################################################[0m
[0mRunning Conv2dRFFTFunction step=8/12 (66.67%)[0m
[0m################################################################################[0m
[W CPUAllocator.cpp:219] Memory block of unknown size was allocated before the profiling started, profiler results will not include the deallocation event
[0m################################################################################[0m
[0mRunning Conv2dRFFTFunction step=9/12 (75.00%)[0m
[0m################################################################################[0m
[0m################################################################################[0m
[0mRunning Conv2dRFFTFunction step=10/12 (83.33%)[0m
[0m################################################################################[0m
[0m################################################################################[0m
[0mRunning Conv2dRFFTFunction step=11/12 (91.67%)[0m
[0m################################################################################[0m
[0m################################################################################[0m
[0mProfile trace saved to /home/edreis/Code/eduardo4jesus/Phd-Research/paper2/src/experiments_cifar100/.profiles/AlexNet_CIFAR100_Conv2dRFFTFunction_date-20240212-071549.json.[0m
[0mProfile saved to /home/edreis/Code/eduardo4jesus/Phd-Research/paper2/src/experiments_cifar100/.profiles/AlexNet_CIFAR100_Conv2dRFFTFunction_date-20240212-071549.pt.[0m
[0mProvided parameters: profile(function=Conv2dRFFTPhasorFunction timestamp=20240212-071549 batch_size=64 profile_name=AlexNet_CIFAR100_Conv2dRFFTPhasorFunction num_classes=100 skip_first=0 wait=4 warmup=4 active=4 repeat=1)[0m
[0mOriginal model architecture is AlexNet(
  (features): Sequential(
    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))
    (1): ReLU(inplace=True)
    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)
    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (4): ReLU(inplace=True)
    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)
    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (7): ReLU(inplace=True)
    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (9): ReLU(inplace=True)
    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (11): ReLU(inplace=True)
    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))
  (classifier): Sequential(
    (0): Dropout(p=0.5, inplace=False)
    (1): Linear(in_features=9216, out_features=4096, bias=True)
    (2): ReLU(inplace=True)
    (3): Dropout(p=0.5, inplace=False)
    (4): Linear(in_features=4096, out_features=4096, bias=True)
    (5): ReLU(inplace=True)
    (6): Linear(in_features=4096, out_features=1000, bias=True)
  )
)[0m
[0mAdopted model architecture is AlexNet(
  (features): Sequential(
    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))
    (1): ReLU(inplace=True)
    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)
    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (4): ReLU(inplace=True)
    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)
    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (7): ReLU(inplace=True)
    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (9): ReLU(inplace=True)
    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (11): ReLU(inplace=True)
    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))
  (classifier): Sequential(
    (0): Dropout(p=0.5, inplace=False)
    (1): Linear(in_features=9216, out_features=4096, bias=True)
    (2): ReLU(inplace=True)
    (3): Dropout(p=0.5, inplace=False)
    (4): Linear(in_features=4096, out_features=4096, bias=True)
    (5): ReLU(inplace=True)
    (6): Linear(in_features=4096, out_features=100, bias=True)
  )
)[0m
[0m(0) parameter.requires_grad = True[0m
[0m(1) parameter.requires_grad = True[0m
[0m(2) parameter.requires_grad = True[0m
[0m(3) parameter.requires_grad = True[0m
[0m(4) parameter.requires_grad = True[0m
[0m(5) parameter.requires_grad = True[0m
[0m(6) parameter.requires_grad = True[0m
[0m(7) parameter.requires_grad = True[0m
[0m(8) parameter.requires_grad = True[0m
[0m(9) parameter.requires_grad = True[0m
[0m(10) parameter.requires_grad = True[0m
[0m(11) parameter.requires_grad = True[0m
[0m(12) parameter.requires_grad = True[0m
[0m(13) parameter.requires_grad = True[0m
[0m(14) parameter.requires_grad = True[0m
[0m(15) parameter.requires_grad = True[0m
[0mProfiling Model AlexNet_CIFAR100_Conv2dRFFTPhasorFunction.[0m
[0m################################################################################[0m
[0mRunning Conv2dRFFTPhasorFunction step=0/12 (0.00%)[0m
[0m################################################################################[0m
[0m################################################################################[0m
[0mRunning Conv2dRFFTPhasorFunction step=1/12 (8.33%)[0m
[0m################################################################################[0m
[0m################################################################################[0m
[0mRunning Conv2dRFFTPhasorFunction step=2/12 (16.67%)[0m
[0m################################################################################[0m
[0m################################################################################[0m
[0mRunning Conv2dRFFTPhasorFunction step=3/12 (25.00%)[0m
[0m################################################################################[0m
[0m################################################################################[0m
[0mRunning Conv2dRFFTPhasorFunction step=4/12 (33.33%)[0m
[0m################################################################################[0m
[0m################################################################################[0m
[0mRunning Conv2dRFFTPhasorFunction step=5/12 (41.67%)[0m
[0m################################################################################[0m
[0m################################################################################[0m
[0mRunning Conv2dRFFTPhasorFunction step=6/12 (50.00%)[0m
[0m################################################################################[0m
[0m################################################################################[0m
[0mRunning Conv2dRFFTPhasorFunction step=7/12 (58.33%)[0m
[0m################################################################################[0m
[0m################################################################################[0m
[0mRunning Conv2dRFFTPhasorFunction step=8/12 (66.67%)[0m
[0m################################################################################[0m
[0m################################################################################[0m
[0mRunning Conv2dRFFTPhasorFunction step=9/12 (75.00%)[0m
[0m################################################################################[0m
[0m################################################################################[0m
[0mRunning Conv2dRFFTPhasorFunction step=10/12 (83.33%)[0m
[0m################################################################################[0m
[0m################################################################################[0m
[0mRunning Conv2dRFFTPhasorFunction step=11/12 (91.67%)[0m
[0m################################################################################[0m
[0m################################################################################[0m
[0mProfile trace saved to /home/edreis/Code/eduardo4jesus/Phd-Research/paper2/src/experiments_cifar100/.profiles/AlexNet_CIFAR100_Conv2dRFFTPhasorFunction_date-20240212-071549.json.[0m
[0mProfile saved to /home/edreis/Code/eduardo4jesus/Phd-Research/paper2/src/experiments_cifar100/.profiles/AlexNet_CIFAR100_Conv2dRFFTPhasorFunction_date-20240212-071549.pt.[0m
[0m################ Profiling ended at 20240212-071715 ################.[0m
